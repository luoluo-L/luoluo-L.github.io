---
title: 'Wearable EDA Quality Model improves SOTA'
date: 2025-06-08
tags:
permalink: /posts/2026/06/blog-post-4/
  - Electrodermal activity
  - Wearables
---

Electrodermal activity (EDA) is a key indicator of sympathetic nervous system activation and a reliable marker of emotional arousal or stress. However, motion artifacts and connectivity issues often degrade EDA signal quality. To enable meaningful interpretation, it is essential to distinguish between high- and low-quality EDA signals.
We propose an EDA signal quality index system leveraging unsupervised pre-trainingâ€”a strategy widely used in natural language processing models such as GPT.  Our approach achieve approximately $8\%$ in ROCAUC improvement compared to SOTA, while requiring only half the training epochs. This demonstrates that even with limited labeled data and a lightweight model, pre-training can significantly enhance EDA quality assessment, making it practical for real-time, wearable health applications.



## Framework

<img src='/images/eda_sqi/framework.png' width = '500'>


## Preliminary Results

Visualizations:

<img src='/images/eda_sqi/prelim_results.png' width = '500'>

AUC Performance on EDABE-Test Recordings

\* Reported performance from cited paper  
â€  Performance from our implementation


All performance reported below are trained on raw EDA data from EDABE.  
Fine-tuned from the Denoise pre-train task achieves highest average AUC at **0.851**, outperforming EDABE by **12%**, and U-Net by **8%**, with a model size only approximately **1%** of the EDABE model.

### Table 1: ROCAUC Performance

| ROCAUC on EDABE-Test                  | Mean (Std)      | Median  | Min    | Max    |
|--------------------------------------|-----------------|---------|--------|--------|
| LSTM-1DCNN\* [1]                     | 0.76 (0.060)    | -       | -      | -      |
| U-Netâ€  [2]                           | 0.788 (0.087)   | 0.809   | 0.652  | 0.896  |
| **(Ours) Denoise-50**                | **0.851 (0.089)** | **0.866** | **0.717** | **0.974** |
| **(Ours) Forecast-50**               | _0.832 (0.088)_ | _0.855_ | 0.694  | 0.947  |
| **(Ours) Denoise & Forecast-200**    | 0.831 (_0.082_) | 0.850   | _0.712_ | 0.946  |


### Table 2: Memory Footprints and Supervised Training Epochs

| Model                    | Memory   | Train Epochs |
|-------------------------|----------|--------------|
| LSTM\* [1]              | 26.74MB  | -            |
| U-Netâ€  [2]              | 0.28MB   | 100 (98)     |
| **Ours**                | 0.28MB   | 50           |

---

### ðŸ“š References

[1] Llanes, L., Carrasco-Ribelles, M., AlcaÃ±iz Raya, M., & MarÃ­n-Morales, J. (2023). *Electrodermal activity artifact correction benchmark (EDABE) (Version 2) [Dataset]*. [https://doi.org/10.17632/w8fxrg4pv5.2](https://doi.org/10.17632/w8fxrg4pv5.2)


[2] Kong, Y., Hossain, M. B., Peitzsch, A., Posada-Quintero, H. F., & Chon, K. H. (2024). *Automatic motion artifact detection in electrodermal activity signals using 1D U-Net architecture*. *Computers in Biology and Medicine*, 182, 109139. [https://doi.org/10.1016/j.compbiomed.2024.109139](https://doi.org/10.1016/j.compbiomed.2024.109139)
